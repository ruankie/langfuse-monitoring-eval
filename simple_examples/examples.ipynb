{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from decorator_example import get_story\n",
    "from langchain_rag_example import get_rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a forgotten library, a young girl opened a dusty book and discovered it was writing her life story as she lived it, each turn of the page revealing her next decision.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_story()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruan/Documents/github/pyconza-2024/simple_examples/../knowledge_base/utils.py:70: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding_function = HuggingFaceEmbeddings(\n",
      "/Users/ruan/Documents/github/pyconza-2024/agent/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/ruan/Documents/github/pyconza-2024/agent/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/ruan/Documents/github/pyconza-2024/simple_examples/../knowledge_base/utils.py:75: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "rag_chain = get_rag_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z0/14mm5wqn6qlfz7yclfhmlp9c0000gn/T/ipykernel_10172/1392805345.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = rag_chain(\"Explain how the different types of agent memory work\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Explain how the different types of agent memory work',\n",
       " 'result': \"In artificial intelligence and cognitive architectures, agent memory refers to the mechanisms by which agents store, retrieve, and utilize information. There are several types of agent memory, each with its own characteristics and functions:\\n\\n1. **Working Memory**: Also known as short-term memory, working memory is a temporary storage system that holds information for a brief period (seconds or minutes). It's used to process and manipulate information in real-time, similar to human working memory. Working memory is often implemented using data structures like stacks or queues.\\n2. **Long-Term Memory**: This type of memory stores information for an extended period (hours, days, weeks, etc.). Long-term memory is responsible for storing knowledge, experiences, and skills that are not currently being used but can be retrieved when needed. In AI systems, long-term memory is often implemented using databases or knowledge graphs.\\n3. **Episodic Memory**: Episodic memory stores specific events or episodes from an agent's past experiences. It's a type of long-term memory that allows the agent to recall and re-experience previous events. Episodic memory is essential for learning, decision-making, and planning in AI systems.\\n4. **Semantic Memory**: Semantic memory stores general knowledge and facts about the world, such as concepts, categories, and relationships between entities. It's a type of long-term memory that provides context and meaning to an agent's experiences. Semantic memory is often used in natural language processing (NLP) and question-answering systems.\\n5. **Procedural Memory**: Procedural memory stores skills, habits, and procedures that are learned through practice or experience. It's a type of long-term memory that enables agents to perform tasks automatically without conscious thought. Procedural memory is essential for robotics, control systems, and other applications where agents need to execute complex procedures.\\n6. **Implicit Memory**: Implicit memory stores information that is not consciously accessible but can influence an agent's behavior or performance. It's a type of long-term memory that affects an agent's habits, preferences, and decision-making processes without the agent being aware of it.\\n\\nThese types of agent memory are not mutually exclusive, and many AI systems use combinations of these mechanisms to achieve their goals. The specific implementation details depend on the application domain, the complexity of the tasks, and the desired level of performance.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain(\"Explain how the different types of agent memory work\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In artificial intelligence and cognitive architectures, agent memory refers to the mechanisms by which agents store, retrieve, and utilize information. There are several types of agent memory, each with its own characteristics and functions:\n",
      "\n",
      "1. **Working Memory**: Also known as short-term memory, working memory is a temporary storage system that holds information for a brief period (seconds or minutes). It's used to process and manipulate information in real-time, similar to human working memory. Working memory is often implemented using data structures like stacks or queues.\n",
      "2. **Long-Term Memory**: This type of memory stores information for an extended period (hours, days, weeks, etc.). Long-term memory is responsible for storing knowledge, experiences, and skills that are not currently being used but can be retrieved when needed. In AI systems, long-term memory is often implemented using databases or knowledge graphs.\n",
      "3. **Episodic Memory**: Episodic memory stores specific events or episodes from an agent's past experiences. It's a type of long-term memory that allows the agent to recall and re-experience previous events. Episodic memory is essential for learning, decision-making, and planning in AI systems.\n",
      "4. **Semantic Memory**: Semantic memory stores general knowledge and facts about the world, such as concepts, categories, and relationships between entities. It's a type of long-term memory that provides context and meaning to an agent's experiences. Semantic memory is often used in natural language processing (NLP) and question-answering systems.\n",
      "5. **Procedural Memory**: Procedural memory stores skills, habits, and procedures that are learned through practice or experience. It's a type of long-term memory that enables agents to perform tasks automatically without conscious thought. Procedural memory is essential for robotics, control systems, and other applications where agents need to execute complex procedures.\n",
      "6. **Implicit Memory**: Implicit memory stores information that is not consciously accessible but can influence an agent's behavior or performance. It's a type of long-term memory that affects an agent's habits, preferences, and decision-making processes without the agent being aware of it.\n",
      "\n",
      "These types of agent memory are not mutually exclusive, and many AI systems use combinations of these mechanisms to achieve their goals. The specific implementation details depend on the application domain, the complexity of the tasks, and the desired level of performance.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
